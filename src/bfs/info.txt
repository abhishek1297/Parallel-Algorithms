compare dynamic parallel vs normal parallel version
 * create diagrams for level sychronization and graph representation
 * compare the level synchronous approach of the cpu and gpu
 * what did I improve rather than traditional gpu implementation
 * atomic operations
 *
 * added device parallelism
 * added hierarchical queues
 * read from research papers also
 *
 *
 *
 * provide time complexity as well as clock cycles reduced
 
 
 The reason why the performance is slower when you directly use warp level queues
 all threads will go through if else statements in the for loop of the kernel
 if all the small level queues become full the else condition takes place
 Now threads may take different paths so it is not necessary that all the threads running will
 perform memory coalescing on the data some may be filling their respective queues while others
 writing data to the global memory. The idea is to use another block level queue such that 
 when warp level becomes full then add it to the block level.
 
 
 The reasons why dfs is not optimal:
 
 Dfs is asynchronous.
 It will search from a single node until all of its children are relaxed.
 Considering real world graphs the outdegree of each node is not unreasonably large.
 But unlike BFS which is launches mulitple threads for all the frontier nodes, DFS will never
 utilize GPU's full capability. Furthermore in DFS, the kernel calls and the number of threads are
 at the mercy of the outdegree at that node. So it might make few calls with heavier workload(highly unlikely)
 or more calls with less workload. and given the fact that GPU performance degrades (as diagram)
 with smaller workload since kernel prologue is a heavy task and should be considered.
 
 Now serial DFS which uses stack provides backtracking. Here no such DS can be used since the node which
 calls the kernel handles all of its adjacent nodes and coloring itself black.  