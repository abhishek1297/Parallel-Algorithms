compare dynamic parallel vs normal parallel version
 * create diagrams for level sychronization and graph representation
 * compare the level synchronous approach of the cpu and gpu
 * what did I improve rather than traditional Gpu implementation
 * atomic operations
 *
 * added device parallelism
 * added hierarchical queues
 * read from research papers also
 *
 *
 *
 * provide time complexity as well as clock cycles reduced
 
 
 The reason why the performance is slower when you directly use warp level queues in my case
 The warp level queues will reduce the number of collisions by a factor of #queues since each thread
 will have its respective sub queue mapped according to its index. In the naive approach, the while filling the
 next queue all the threads follow the same path with less number of divergence due to conditions whereas in hierarchical/blocked queue
 approach threads diverge and take different paths thus leading reduction in performance. The naive approach
maximizes the global memory bandwidth compared to hierarchical or blocked queue approach.
 
 This is probably because of the density and outdegree of the graph. In this project, I have only worked with
 real-world graphs which are not sparse. 
 Although I improved coalescing implementation by iterating over all of the queues
 in a single loop by manipulating addresses but it seems the calculations and conditional divergence resists the
 performance to be increased by a large factor.
 
 
 
 Hierarchical Queue Management:
 As suggested in the paper [x] We can avoid the collisions at the global level as well as the block level by
 adding a new level of queue at the warp level. The author of the paper suggests us to three queues but in
 my implementation I have only used two since both warp level and block level queues reside in the shared memory.
 Copying data from warp queue to the block queue seems unresonable because of copying the data at the same level
 before it is copied to the global memory.

Texture memory fail:
I had hoped due to spatial locality the latency is reduced when global memory is accessed through
texture reference. But in my case it was not able to achieve correct results. Furthermore, The execution of hierarchical approach
was an asynchronous exit. Also in the case of naive approach the execution time doubled. So I decided to avoid the usage of 
texture memory. (Add more reasoning) The number of vertices in the graphs I use is more than a million so it is not possible to hold
these large arrays in constant memory which is also aggresively cached for read-only access.
 
 The reasons why dfs is not optimal:
 
 Dfs is asynchronous.
 It will search from a single node until all of its children are relaxed.
 Considering real world graphs the outdegree of each node is not unreasonably large.
 But unlike BFS which is launches mulitple threads for all the frontier nodes, DFS will never
 utilize GPU's full capability. Furthermore in DFS, the kernel calls and the number of threads are
 at the mercy of the outdegree at that node. So it might make few calls with heavier workload(highly unlikely)
 or more calls with less workload. and given the fact that GPU performance degrades (as diagram)
 with smaller workload since kernel prologue is a heavy task and should be considered.
 
 Now serial DFS which uses stack provides backtracking. Here no such DS can be used since the node which
 calls the kernel handles all of its adjacent nodes and coloring itself black.  